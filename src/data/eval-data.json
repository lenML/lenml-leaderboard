[
  {
    "model": "fblgit/UNA-SimpleSmaug-34b-v1beta",
    "size": 34.4,
    "quantization": "iq3_ks",
    "lh": 43.26,
    "lr": 0.86,
    "lc": null,
    "ll": null
  },
  {
    "model": "zetasepic/Qwen2.5-32B-Instruct-abliterated-v2",
    "size": 32.8,
    "quantization": "q3_k_m",
    "lh": 40.12,
    "lr": 0.05,
    "ll": 86.70626347384285,
    "lc": 88.66666666666667
  },
  {
    "model": "AiCloser/Qwen2.5-32B-AGI",
    "size": 32.8,
    "quantization": "q3_k_m",
    "lh": 38.87,
    "lr": 0.16
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-14B-Instruct-abliterated-v4",
    "size": 14.8,
    "quantization": "q4_k_m",
    "lh": 37.61,
    "lr": 0.17
  },
  {
    "model": "TheDrummer/Star-Command-R-32B-v1",
    "size": 32.8,
    "quantization": "q3_k_m",
    "lh": 37.3,
    "lr": 0.75
  },
  {
    "model": "CohereForAI/aya-expanse-32b",
    "size": 32.8,
    "quantization": "q3_k_m",
    "lh": 37.3,
    "lr": 0.94
  },
  {
    "model": "anthracite-org/magnum-v4-27b",
    "size": 27.2,
    "quantization": "q4_k_m",
    "lh": 36.36,
    "lr": 1.0
  },
  {
    "model": "huihui-ai/Qwen2.5-Coder-32B-Instruct-abliterated",
    "size": 32.8,
    "quantization": "q3_k_m",
    "lh": 33.54,
    "lr": 0.86
  },
  {
    "model": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
    "size": 7.62,
    "quantization": "q4_k_m",
    "lh": 32.28,
    "lr": 0.13
  },
  {
    "model": "byroneverson/gemma-2-27b-it-abliterated",
    "size": 27.2,
    "quantization": "q4_k_m",
    "lh": 32.0,
    "lr": 0.47,
    "ll": 74.47939883518455,
    "lc": 70.80000000000001
  },
  {
    "model": "IlyaGusev/saiga_nemo_12b",
    "size": 12.2,
    "quantization": "q4_k_m",
    "lh": 30.4,
    "lr": 1.0
  },
  {
    "model": "huihui-ai/Qwen2.5-Coder-7B-Instruct-abliterated",
    "size": 7.62,
    "quantization": "q4_k_m",
    "lh": 29.78,
    "lr": 0.22
  },
  {
    "model": "mlx-community/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2",
    "size": 7.62,
    "quantization": "q3_k_m",
    "lh": 29.7,
    "lr": 0.08
  },
  {
    "model": "ifable/gemma-2-Ifable-9B",
    "size": 9.24,
    "quantization": "q4_k_m",
    "lh": 29.5,
    "lr": 0.88
  },
  {
    "model": "TheDrummer/Tiger-Gemma-9B-v3",
    "size": 9.24,
    "quantization": "q4_k_m",
    "lh": 29.46,
    "lr": 1
  },
  {
    "model": "IlyaGusev/gemma-2-9b-it-abliterated",
    "size": 9.24,
    "quantization": "q4_k_m",
    "lh": 27.27,
    "lr": 0.11,
    "ll": 74.70141995258126,
    "lc": 65.4
  },
  {
    "model": "princeton-nlp/gemma-2-9b-it-SimPO",
    "size": 9.24,
    "quantization": "q4_k_m",
    "lh": 26.6,
    "lr": 0.88
  },
  {
    "model": "CohereForAI/aya-expanse-8b",
    "size": 8.03,
    "quantization": "q4_k_m",
    "lh": 26.01,
    "lr": 0.916
  },
  {
    "model": "mlabonne/Hermes-3-Llama-3.1-8B-lorablated",
    "size": 8.03,
    "quantization": "q4_k_m",
    "lh": 25.7,
    "lr": 0.5,
    "ll": 47.34381178852976,
    "lc": 86.76666666666667
  },
  {
    "model": "byroneverson/Mistral-Small-Instruct-2409-abliterated",
    "size": 12.2,
    "quantization": "q4_k_m",
    "lh": 22.88,
    "lr": 0.86
  },
  {
    "model": "MarinaraSpaghetti/NemoMix-Unleashed-12B",
    "size": 12.2,
    "quantization": "q4_k_m",
    "lh": 19.12,
    "lr": 0.72
  },
  {
    "model": "huihui-ai/Qwen2.5-3B-Instruct-abliterated",
    "size": 3.09,
    "quantization": "q6_k",
    "lh": 17.86,
    "lr": 0.22
  },
  {
    "model": "IlyaGusev/gemma-2-2b-it-abliterated",
    "size": 2.61,
    "quantization": "q8_0",
    "lh": 16.3,
    "lr": 0.22,
    "ll": 70.86505116479596,
    "lc": 78.06666666666666
  },
  {
    "model": "natong19/Mistral-Nemo-Instruct-2407-abliterated",
    "size": 12.2,
    "quantization": "q4_k_m",
    "lh": 15.67,
    "lr": 0.27
  },
  {
    "model": "nvidia/Nemotron-4-Mini-Hindi-4B-Instruct",
    "size": 4.19,
    "quantization": "q6_k",
    "lh": 14.42,
    "lr": 0.77
  },
  {
    "model": "SicariusSicariiStuff/Phi-3.5-mini-instruct_Uncensored",
    "size": 3.82,
    "quantization": "q6_k",
    "lh": 3.44,
    "lr": 0.083
  },
  {
    "model": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
    "size": 1.1,
    "quantization": "Q4_0",
    "lh": 2.2,
    "lr": 1
  },
  {
    "model": "CohereForAI/c4ai-command-r-plus",
    "size": 104,
    "quantization": "iq1_m",
    "lh": 32,
    "lr": null
  },
  {
    "model": "fblgit/TheBeagle-v2beta-32B-MGS",
    "size": 32.8,
    "quantization": "q4_k_s",
    "lh": 41.37,
    "lr": 0.94
  },
  {
    "model": "SaisExperiments/Gemma-2-2B-Opus-Instruct",
    "size": 2.61,
    "quantization": "q6_k",
    "lh": 19.12,
    "lr": 1,
    "ll": 54.598902412282484,
    "lc": 87.63333333333333
  },
  {
    "model": "lenML/aya-expanse-8b-abliterated",
    "size": 8.03,
    "quantization": "q4_k_m",
    "lh": 25.391849529780565,
    "lr": 0.52,
    "ll": 73.36891621336788,
    "lc": 93.89999999999999
  },
  {
    "model": "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored",
    "size": 10.7,
    "quantization": "q4_k_m",
    "lh": 12.539184952978054,
    "lr": 0.001,
    "ll": 39.61161443738214,
    "lc": 97.89999999999999
  },
  {
    "model": "AALF/gemma-2-27b-it-SimPO-37K-100steps",
    "size": 27.2,
    "quantization": "q4_k_s",
    "lh": 31.03448275862069,
    "lr": 0.8611,
    "ll": 72.7901405321862,
    "lc": 91.76666666666667
  },
  {
    "model": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24",
    "size": 12.2,
    "quantization": "q4_k_s",
    "lh": 32.288401253918494,
    "lr": 0.8611,
    "ll": 70.07528015634581,
    "lc": 75.96666666666668
  },
  {
    "model": "Vikhrmodels/Vikhr-Qwen-2.5-0.5b-Instruct",
    "size": 0.494,
    "quantization": "q6_k",
    "lh": 14.420062695924765,
    "lr": 0.583,
    "ll": 47.70607331750326,
    "lc": 63.6
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v2-9B",
    "size": 9.24,
    "quantization": "q4_k_s",
    "lh": 25.705329153605017,
    "lr": 0.611,
    "ll": 58.17430575196378,
    "lc": 92.23333333333333
  }
]
